{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45e4f8a-65be-4d1c-8e19-1af90767346b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Trainer,\n",
    "    Seq2SeqTrainer,\n",
    "    PreTrainedTokenizerFast,\n",
    ")\n",
    "from functools import partial\n",
    "from transformers.models.qwen2.tokenization_qwen2_fast import Qwen2TokenizerFast\n",
    "from transformers.models.qwen2.modeling_qwen2 import Qwen2ForCausalLM, Qwen2ForSequenceClassification\n",
    "from peft import PrefixTuningConfig, get_peft_model, TaskType\n",
    "from peft.peft_model import PeftModelForCausalLM, PeftModelForSequenceClassification\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "from transformers import GenerationConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb213b7-2c06-4ffe-9105-2a4a106ff370",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/root/llm_adv_qa/sft')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dir = Path(os.getcwd())\n",
    "file_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb7e0ac4-2bab-42b1-8eeb-e046ddb041db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir='/root/autodl-tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9624ccc9-0a61-4078-910d-ef1522024dd8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/autodl-tmp/.cache/modelscope/hub/tiansz/bert-base-chinese'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = str(\n",
    "        Path(cache_dir, \".cache/modelscope/hub/tiansz/bert-base-chinese\")\n",
    "    )\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c37a4b-67b3-4e98-99e5-5f029ca504a7",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['class', 'question', 'prompt'],\n",
       "        num_rows: 1087\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['class', 'question', 'prompt'],\n",
       "        num_rows: 119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = Path(file_dir.parent, \"resources\", \"dataset\", \"classification\", \"train.jsonl\")\n",
    "test_file = Path(file_dir.parent, \"resources\", \"dataset\", \"classification\", \"test.jsonl\")\n",
    "dataset = load_dataset(\n",
    "    \"json\", data_files={\"train\": train_file.as_posix(), \"test\": test_file.as_posix()}\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd5aa49-5fee-4df6-b965-68fd0835aadf",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de543c8-b7f5-4c6d-beec-b252ecd6f56c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.tokenization_bert_fast.BertTokenizerFast"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62cded96-a34c-4d4a-bced-a2046bef5bb1",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class', 'question', 'prompt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_cols = dataset[\"train\"].column_names\n",
    "original_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74837754-a1b3-4006-bab0-cf95cac33e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label={\n",
    "    0: \"A\",\n",
    "    1: \"B\",\n",
    "    2: \"C\",\n",
    "    3: \"D\",\n",
    "    4: \"E\",\n",
    "    5: \"F\"\n",
    "}\n",
    "\n",
    "label2id={\n",
    "    \"A\": 0,\n",
    "    \"B\": 1,\n",
    "    \"C\": 2,\n",
    "    \"D\": 3,\n",
    "    \"E\": 4,\n",
    "    \"F\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea4ad71-a7b4-4fee-9dd6-89137eeb2562",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_training_data(\n",
    "    example,\n",
    "    tokenizer: PreTrainedTokenizerFast,\n",
    "    max_source_len: int = 512,\n",
    "    max_output_len: int = 1,\n",
    "    ignore_pad_token_for_loss: bool = True,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    example:\n",
    "      {\n",
    "          \"id\": 0,\n",
    "          \"question_prompt\": \"xxxx\",\n",
    "          \"question\": \"xxx\",\n",
    "          \"query\": \"F\"\n",
    "      },\n",
    "\n",
    "    return:\n",
    "        {\"input_ids:[], attention_mask:[], labels:[]}\n",
    "\n",
    "    build inputs with format `X Y <eos> <pad>...` and labels with format `<pad> ... <pad> Y <eos><pad>...`\n",
    "    \"\"\"\n",
    "    max_seq_len = max_source_len + max_output_len + 1\n",
    "\n",
    "    x: str = example[\"question_prompt\"]\n",
    "    y: str = example[\"query\"]\n",
    "\n",
    "    x_ids = tokenizer.encode(\n",
    "        text=x,\n",
    "        truncation=True,\n",
    "        max_length=max_source_len,\n",
    "    )\n",
    "\n",
    "    y_ids = tokenizer.encode(\n",
    "        text=y,\n",
    "        truncation=True,\n",
    "        max_length=max_output_len,\n",
    "    )\n",
    "\n",
    "    x_len = len(x_ids)\n",
    "    input_ids = x_ids + y_ids + [tokenizer.eos_token_id]\n",
    "    labels = [tokenizer.pad_token_id] * x_len + y_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "    # paddding\n",
    "    pad_len = max_seq_len - len(input_ids)\n",
    "    input_ids = input_ids + [tokenizer.pad_token_id] * pad_len\n",
    "    labels = labels + [tokenizer.pad_token_id] * pad_len\n",
    "    assert len(input_ids) == len(labels) == max_seq_len\n",
    "\n",
    "    if ignore_pad_token_for_loss:\n",
    "        labels = [\n",
    "            (label if label != tokenizer.pad_token_id else -100) for label in labels\n",
    "        ]\n",
    "\n",
    "    return {\"input_ids\": input_ids, \"labels\": labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "addb1334-adfe-406d-bef7-8512d7297866",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_training_data_for_cls(\n",
    "    example,\n",
    "    tokenizer: PreTrainedTokenizerFast,\n",
    "    label2id: Dict,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    example:\n",
    "      {\n",
    "          \"prompt\": \"xxxx\",\n",
    "          \"question\": \"xxx\",\n",
    "          \"class\": \"F\"\n",
    "      },\n",
    "\n",
    "    return:\n",
    "        {\"input_ids:[1,2,3,4,5], attention_mask:[1,1,1,1,1], labels:0}\n",
    "\n",
    "    \"\"\"\n",
    "    x: str = example[\"prompt\"]\n",
    "    y: str = example[\"class\"]\n",
    "    xx = tokenizer(x, truncation=True)\n",
    "    label = label2id[y]\n",
    "    xx['labels'] = label\n",
    "    return xx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c796b734-5eb8-4158-ae4d-b8f0593c4247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_func = partial(preprocess_training_data_for_cls, tokenizer=tokenizer, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d00928d9-6690-4003-b729-5bc3d22b8b32",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_set = dataset[\"test\"].map(\n",
    "        partial(preprocess_func, tokenizer=tokenizer),\n",
    "        remove_columns=original_cols,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb2ab519-8e32-4c4e-84e7-3e09fe095989",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 6435, 7309, 100, 7448, 2128, 4906, 2825,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 6435, 7309, 100, 1071, 800, 2418, 3119, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 6435, 7309, 100, 9960, 2399, 5433, 2949,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 6435, 7309, 100, 2123, 3797, 2548, 3208,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 6435, 7309, 100, 8439, 2399, 2600, 6566,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>[101, 6435, 7309, 100, 6435, 2990, 897, 1298, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>[101, 6435, 7309, 100, 2990, 897, 5650, 2533, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>[101, 6435, 7309, 100, 704, 4906, 7032, 6568, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>[101, 6435, 7309, 100, 7270, 3309, 5500, 3326,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>[101, 6435, 7309, 100, 6435, 7309, 8024, 1045,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_ids  \\\n",
       "0    [101, 6435, 7309, 100, 7448, 2128, 4906, 2825,...   \n",
       "1    [101, 6435, 7309, 100, 1071, 800, 2418, 3119, ...   \n",
       "2    [101, 6435, 7309, 100, 9960, 2399, 5433, 2949,...   \n",
       "3    [101, 6435, 7309, 100, 2123, 3797, 2548, 3208,...   \n",
       "4    [101, 6435, 7309, 100, 8439, 2399, 2600, 6566,...   \n",
       "..                                                 ...   \n",
       "114  [101, 6435, 7309, 100, 6435, 2990, 897, 1298, ...   \n",
       "115  [101, 6435, 7309, 100, 2990, 897, 5650, 2533, ...   \n",
       "116  [101, 6435, 7309, 100, 704, 4906, 7032, 6568, ...   \n",
       "117  [101, 6435, 7309, 100, 7270, 3309, 5500, 3326,...   \n",
       "118  [101, 6435, 7309, 100, 6435, 7309, 8024, 1045,...   \n",
       "\n",
       "                                        token_type_ids  \\\n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "..                                                 ...   \n",
       "114  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "115  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "116  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "117  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "118  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                        attention_mask  labels  \n",
       "0    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
       "1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       5  \n",
       "2    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       2  \n",
       "3    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       2  \n",
       "4    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       4  \n",
       "..                                                 ...     ...  \n",
       "114  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
       "115  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       2  \n",
       "116  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
       "117  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       5  \n",
       "118  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       2  \n",
       "\n",
       "[119 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df536850-2ddc-4602-9e1f-7c919831b5d9",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = dataset[\"train\"].map(\n",
    "        partial(preprocess_func, tokenizer=tokenizer),\n",
    "        remove_columns=original_cols,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "858266a8-3071-4973-8e1e-6dd7522cfc59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 6435, 7309, 100, 2769, 2682, 4761, 6887,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 6435, 7309, 100, 3800, 1085, 1765, 4157,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 6435, 7309, 100, 1762, 8439, 2399, 8024,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 6435, 7309, 100, 1762, 6205, 2128, 3800,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 6435, 7309, 100, 1065, 2336, 7942, 3777,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>[101, 6435, 7309, 100, 945, 3345, 4294, 7415, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>[101, 6435, 7309, 100, 3343, 2336, 6237, 4636,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>[101, 6435, 7309, 100, 8439, 2399, 704, 6823, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>[101, 6435, 7309, 100, 1762, 9960, 2399, 8024,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>[101, 6435, 7309, 100, 1762, 1921, 3823, 3800,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1087 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_ids  \\\n",
       "0     [101, 6435, 7309, 100, 2769, 2682, 4761, 6887,...   \n",
       "1     [101, 6435, 7309, 100, 3800, 1085, 1765, 4157,...   \n",
       "2     [101, 6435, 7309, 100, 1762, 8439, 2399, 8024,...   \n",
       "3     [101, 6435, 7309, 100, 1762, 6205, 2128, 3800,...   \n",
       "4     [101, 6435, 7309, 100, 1065, 2336, 7942, 3777,...   \n",
       "...                                                 ...   \n",
       "1082  [101, 6435, 7309, 100, 945, 3345, 4294, 7415, ...   \n",
       "1083  [101, 6435, 7309, 100, 3343, 2336, 6237, 4636,...   \n",
       "1084  [101, 6435, 7309, 100, 8439, 2399, 704, 6823, ...   \n",
       "1085  [101, 6435, 7309, 100, 1762, 9960, 2399, 8024,...   \n",
       "1086  [101, 6435, 7309, 100, 1762, 1921, 3823, 3800,...   \n",
       "\n",
       "                                         token_type_ids  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "1082  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1083  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1084  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1085  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1086  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                         attention_mask  labels  \n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       2  \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       4  \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       2  \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       4  \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       1  \n",
       "...                                                 ...     ...  \n",
       "1082  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       2  \n",
       "1083  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       2  \n",
       "1084  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
       "1085  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       2  \n",
       "1086  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       4  \n",
       "\n",
       "[1087 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "804305db-5f1e-45b1-b09c-031161cf1366",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /root/autodl-tmp/.cache/modelscope/hub/tiansz/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.modeling_bert.BertForSequenceClassification"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path, num_labels=6,id2label=id2label, label2id=label2id\n",
    ")\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37a955cc-13b3-4ba2-a966-8cad8f5c68ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"/root/autodl-tmp/.cache/modelscope/hub/tiansz/bert-base-chinese\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"A\",\n",
       "    \"1\": \"B\",\n",
       "    \"2\": \"C\",\n",
       "    \"3\": \"D\",\n",
       "    \"4\": \"E\",\n",
       "    \"5\": \"F\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"A\": 0,\n",
       "    \"B\": 1,\n",
       "    \"C\": 2,\n",
       "    \"D\": 3,\n",
       "    \"E\": 4,\n",
       "    \"F\": 5\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.47.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02fda33b-21a4-48db-a968-51ac6100c014",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/root/llm_adv_qa/resources/sft_models/classification')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_dir = Path(\n",
    "        file_dir.parent, \"resources\", \"sft_models\", \"classification\"\n",
    "    )\n",
    "model_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28ddf705-2158-4520-bf8d-c85ac5b61f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_output_dir = Path(model_output_dir, \"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe269ba8-e76b-490f-acad-cee6af7397ed",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred, tokenizer: PreTrainedTokenizerFast):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # rouge = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    score_dict = {}\n",
    "    acc_total = len(predictions)\n",
    "    acc_correct = 0\n",
    "    for prediction, label in zip(decoded_preds, decoded_labels):\n",
    "        # Accuracy\n",
    "        if prediction[-1].upper() == label.upper():\n",
    "            acc_correct += 1\n",
    "        # print(f\"new token: '{tokenizer.encode(prediction[-1])}'\\nlabel: '{label}'\\n\")\n",
    "        # print(\"--------------\")\n",
    "        # Rouge\n",
    "        # rouge_scores = rouge.score(prediction, label)\n",
    "        # for k, v in rouge_scores.items():\n",
    "        #     if score_dict.get(k) is None:\n",
    "        #         score_dict[k] = []\n",
    "        #     score_dict[k].append(v.fmeasure)\n",
    "    # accuracy\n",
    "    score_dict[\"accuracy\"] = acc_correct / acc_total\n",
    "    # length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    score_dict[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(np.mean(v), 4) for k, v in score_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33a45674-d03c-4613-8e9f-bd7e0a7b6194",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_for_cls(eval_pred, tokenizer: PreTrainedTokenizerFast):\n",
    "    preds, labels = eval_pred\n",
    "    acc_total = len(preds)\n",
    "    acc_correct = 0\n",
    "    for pred, label in zip(preds, labels):\n",
    "        prediction = np.argmax(pred, axis=-1)\n",
    "        if prediction == label:\n",
    "            acc_correct += 1\n",
    "    return {\"accuracy\": acc_correct/acc_total}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "142917f3-f0ca-4626-8197-c99afdd5b6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_func = partial(compute_metrics_for_cls, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b28e7bd5-246b-4d8e-9f47-788ce2d2d448",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "        output_dir=str(model_output_dir),\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        logging_steps=0.05,\n",
    "        num_train_epochs=5,\n",
    "        learning_rate=2e-5,\n",
    "        warmup_ratio=0.05,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=0.05,\n",
    "        save_strategy=\"steps\",\n",
    "        save_total_limit=1,\n",
    "        save_steps=0.05,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_accuracy\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34c6acbb-46b8-4404-8e40-108f219178f2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "smoke_run = False\n",
    "\n",
    "if smoke_run:\n",
    "    validation_set = validation_set.select(range(8))\n",
    "    train_set = train_set.select(range(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a25b2f56-c19d-4ca7-bc5c-bb1cc53f2cd8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7719/3148274461.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=train_set,\n",
    "        eval_dataset=validation_set,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "        compute_metrics=metrics_func,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b726806-0929-4fad-b6d1-f424064e1ca6",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if smoke_run:\n",
    "    trainer.evaluate(eval_dataset=validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7a17941-4a51-4049-98c3-54954d8bd2c2",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='680' max='680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [680/680 03:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.652100</td>\n",
       "      <td>1.376862</td>\n",
       "      <td>0.436975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.223000</td>\n",
       "      <td>1.040381</td>\n",
       "      <td>0.630252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>0.252569</td>\n",
       "      <td>0.957983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.208900</td>\n",
       "      <td>0.272385</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.202603</td>\n",
       "      <td>0.957983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.238700</td>\n",
       "      <td>0.145921</td>\n",
       "      <td>0.974790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.156300</td>\n",
       "      <td>0.011729</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>0.109500</td>\n",
       "      <td>0.074524</td>\n",
       "      <td>0.983193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.056931</td>\n",
       "      <td>0.991597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.117680</td>\n",
       "      <td>0.966387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.048624</td>\n",
       "      <td>0.991597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.058776</td>\n",
       "      <td>0.991597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.064012</td>\n",
       "      <td>0.991597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>476</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.060605</td>\n",
       "      <td>0.991597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.063617</td>\n",
       "      <td>0.991597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.077124</td>\n",
       "      <td>0.983193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>578</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.075734</td>\n",
       "      <td>0.983193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>612</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.078637</td>\n",
       "      <td>0.983193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>646</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.077605</td>\n",
       "      <td>0.983193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.078777</td>\n",
       "      <td>0.983193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not smoke_run:\n",
    "    trainer.train()\n",
    "    trainer.save_model(output_dir=best_model_output_dir)\n",
    "    trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7e1d15f-c5e0-41d3-a052-c6037b50bb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU modelscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94ce4298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "AK = os.environ['MODEL_SCOPE_AK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d644d-0702-4108-8895-0ffebc72632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope.hub.api import HubApi\n",
    "\n",
    "api = HubApi()\n",
    "api.login(AK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71a2567b-b699-4f2b-8955-a821cc574ce3",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Blackoutta/bert-base-chinese-sft-intention'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelscope.hub.constants import Licenses, ModelVisibility\n",
    "\n",
    "username = 'Blackoutta'\n",
    "model_name = 'bert-base-chinese-sft-intention'\n",
    "model_id = username + \"/\" + model_name,\n",
    "model_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f28426e-8436-42a9-895c-d39ae9f0622e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 17:09:29,698 - modelscope - WARNING - No configuration.json file found in /root/llm_adv_qa/resources/sft_models/classification/best, creating a default one.\n",
      "2024-12-21 17:09:29,946 - modelscope - INFO - Creating new model [Blackoutta/bert-base-chinese-sft-intention]\n",
      "2024-12-21 17:09:32,659 - modelscope - INFO - Pushing folder /root/llm_adv_qa/resources/sft_models/classification/best as model Blackoutta/bert-base-chinese-sft-intention.\n",
      "2024-12-21 17:09:32,660 - modelscope - INFO - Total folder size 1.14 GB, this may take a while depending on actual pushing size...\n",
      "2024-12-21 17:09:41,439 - modelscope - INFO - [master c14d01e] 'upload model'\n",
      " 13 files changed, 42678 insertions(+), 47 deletions(-)\n",
      " delete mode 100644 README.md\n",
      " create mode 100644 config.json\n",
      " create mode 100644 configuration.json\n",
      " create mode 100644 model.safetensors\n",
      " create mode 100644 optimizer.pt\n",
      " create mode 100644 rng_state.pth\n",
      " create mode 100644 scheduler.pt\n",
      " create mode 100644 special_tokens_map.json\n",
      " create mode 100644 tokenizer.json\n",
      " create mode 100644 tokenizer_config.json\n",
      " create mode 100644 trainer_state.json\n",
      " create mode 100644 training_args.bin\n",
      " create mode 100644 vocab.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "api.push_model(\n",
    "    model_id=model_id[0], # 如果model_id对应的模型库不存在，将会被自动创建\n",
    "    model_dir=best_model_output_dir # 指定本地模型所在目录\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29855a16-dd8e-4a6e-806e-a9a12477c03e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
